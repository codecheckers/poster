---
type: poster
topic: reproducibility and good scientific practice
key words: reproducible research, code execution, peer review

# submission at https://de-rse23.sciencesconf.org/submission/submit
---

# RSEng expertise for scientific peer review with CODECHECK

Data and software are the foundation for a vast variety and volume of scientific research. Computational research is used in most scientific disciplines to make sense of small or huge datasets using everything from one-off scripts to high-performance computing infrastructures. At some point, all these works are presented to a scientific community and in the current academic reality, the publication of a research paper is still a crucial step for the recognition of research outputs and career advancement. While research papers are increasingly accompanied by data and software to ensure transparency, reproducibility, and reusability, the inspection of these building blocks is not a common part of the publication and peer review process. The CODECHECK initiative tries to make code execution standard practice in peer review. In this work, we present the CODECHECK principles and implementation options. We highlight the particular possibilities for research software engineers to participate in academic peer review as codecheckers and how good scientific and development practices can be spread, encouraged, and potentially enforced through codechecking.